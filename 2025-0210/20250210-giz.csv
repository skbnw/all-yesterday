headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
iPhoneにハイレゾワイヤレスを…。Snapdragonさんお願いします（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/c9a72a50dc9efd1c464360eb6f73509c7f2cd05a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000019-giz-000-1-view.jpg?exp=10800,2025-02-10T21:00:02+09:00,2025-02-10T21:00:02+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,748,"iPhoneにハイレゾワイヤレスを…。Snapdragonさんお願いします
SnapdragonとiPhone、奇跡のコラボといってよいでしょう。

Bluetooth対応コーデックを、頑なに増やさずにここまできているiPhone。超低遅延や、ハイレゾ対応のワイヤレスイヤホンが増えてきているなか、最新サウンドを試したくてやきもきしちゃっている方もいることでしょう。
【全画像をみる】iPhoneにハイレゾワイヤレスを…。Snapdragonさんお願いします
Questyleが3月に発売するというUSBドングル「QCC Dongle PRO」は、1つの救いとなるかもしれません。ちっさいUSBメモリのように見えますが、最新世代のBluetoothトランスミッターなんです。

キモとなっているのは、Snapdragon S5を搭載した、Qualcomm S5 Sound Platform対応製品だということ。iPhoneが未サポートだったLE Audio（LC3）、 aptX、aptX HD、aptX Adaptive、LDACイヤホンが使えるようになります。高ビットレートコーデックも、超低遅延コーデックもカバーしてくれたのはうれしいねえ。MFi認証を受けた製品というのも安心ポイントですね。

iPhoneだけではありません。iPadでも、PS5でもSwitchでも使えますよ。もちろんWindowsでも、Macでも、（必要ないかもだけど）Androidでも、ね。

またLDACは使えないけど、格安っぽいSnapdragon S3搭載「QCC Dongle」も登場するとのこと。価格はまだ未公開ですが、iPhoneのオーディオ環境に一石を投じそうなこのドングル。期待したい！
武者良太",[],[]
Gemini Liveがさらに人間っぽく。今年後半、劇的な進化を遂げる…のか？（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/e318cc34fcff7c990a651991146a86e76a50318e,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000018-giz-000-1-view.jpg?exp=10800,2025-02-10T19:30:02+09:00,2025-02-10T19:30:02+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,2281,"Gemini Liveがさらに人間っぽく。今年後半、劇的な進化を遂げる…のか？
AIと話している自分がおかしくて噴き出しちゃうので会話が続かないのだ…。

GoogleのGemini Liveはユーザーと会話できるんですけど、その会話が弾むかと言われると微妙なところ。でも、Googleとしては少なくとも「リアルな話し相手」みたいに感じてほしいらしいんですよね。
【全画像をみる】Gemini Liveがさらに人間っぽく。今年後半、劇的な進化を遂げる…のか？
で、AIの性能が上がるにつれてできることも広がってきているようで、今回のアップデートでは「クラウド上のAIとチャットしてる」というよりも、「スマホにAIから電話がかかってきた」みたいな演出になっているのだとか。
Gemini LiveのUIが電話っぽく変更
Googleは1月末にGemini 2.0 Flashモデルをアップデートし、Geminiアプリを利用するすべてのユーザーが無料で使えるようにしました。つまり、もう有料サブスクに加入しなくてもOKってわけです。

9to5Googleによると、このアップデートには「隠し変更」もあったらしく、Gemini Liveの通知がこれまで以上に人間っぽく見えるようになったとのこと。AIとの距離感がまた一歩近づいた感じ？

以前のAndroid版Gemini Liveでは、バックグラウンドでの実行中にアプリを閉じると、シンプルな通知が表示されるだけでした。でも、新バージョンではこれがまるで通話画面みたいなデザインに変更され、「終了」か「一時停止」を選べるようになりました。

UIはこんな感じ。

さらに、ロック画面では「GeminiとLiveで会話」「マイクがONになっているため、Geminiと音声で会話できます」という通知が表示されます。比較的短時間で自動的に一時停止モードに入りますが、その場合はもう一度アプリを開くか、「OK Google、 話そう」などと声をかけると会話を継続できるようです。
Project Astra機能搭載の前兆？
今回の小さな変更は、Googleが2025年に向けてAIをどう進化させようとしているのかが見えてくるアップデートでもあります。Gemini Liveはすでにユーザーと会話できるだけでなく、最近は写真や動画の内容を理解する機能まで追加されました。

さらに将来的には、Google DeepMindの「Project Astra 」から視覚認識機能を搭載する計画も進行中とのこと。そのため、Gemini Liveはスマホの通常操作を邪魔することなく、バックグラウンドでより自然に動作する必要がありそうです。
Gemini 2.0のアップデートは続く
Googleは現在、Gemini 2.0をさらにアップデートし、用途に応じた大小さまざまなAIモデルを追加中。2月5日に公開されたブログ記事では、“実験的な”Gemini 2.0 Proがお披露目され、これまでで最も強力なユーザー向けモデルと紹介されていました（こちらGoogle Japanのブログでは言及がありません）。

Gemini 2.0 Proは特にプログラマー向けに設計されていて、Gemini Advancedの有料プランに加入すれば誰でも利用可能とのこと。AIを駆使して作業を効率化したいエンジニアにとっては、なかなかおもしろい選択肢になりそうですね。

ところで、Googleの最新モデルは本当にそこまで優秀なんでしょうか？ 同社の説明では、ほとんどのベンチマークでGemini 2.0 Flashを上回っているそうですが、「事実に基づいた正確な回答を求めるテスト」だけは例外だったとのこと。それ、例外になったらあかんやつやん。

一方、Gemini 2.0 Flash-Liteは、必要な電力がGemini 1.5 Flashと同じなのに、より正確な回答を出せるとGoogleは主張しています。

ちなみに、この新モデルの発表は、OpenAIがo3推論モデルを公開した直後でした。OpenAIは1月末、さらに軽量バージョンのo3-mini推論モデルも発表。AIの進化競争は線路のようにどこまでも続きそうです。
Geminiは今年後半、劇的な進化を遂げる…はず
Samsung（サムスン）の最新スマホGalaxy S25の目玉機能のひとつとして、Geminiとのクロスアプリ機能が搭載されました。電源ボタンを長押しするだけで、テキストメッセージをカレンダーの予定に変換するといった簡単な操作がハンズフリーでできるとのこと。めちゃくちゃ便利そうに聞こえますよね？

でも、米Gizmodoのテストによると、実際のAI機能はかなり平凡だったらしく、単純なタスクは問題なくこなせるものの、複雑な処理にはまだ難があるとのこと。もしAIの回答をいちいちチェックしなきゃいけないなら、自分でやったほうが早いかもしれませんね。

Googleは今年後半のGoogle I/O 2025やPixel 10のリリースに向けて、最高のモバイルAI機能を温存しているようです。SamsungのAIがイマイチだったこともあって、Googleとしては「これが本物のAI体験だ！」とユーザーを驚かせせるつもりなんでしょう。でも、これほどの努力とPRが価値あるものだったのかどうか、その答えはもう少し待つ必要がありそうです。
Kenji P. Miyajima",[],[]
Google「武器目的でAIを利用しない」という誓約文をシレッと消す（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/cb103e9d9a35e0beb3745d0613e2c6daaf022544,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000017-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,816,"Google「武器目的でAIを利用しない」という誓約文をシレッと消す
なんだか不穏な空気…？

Googleはこれまで「武器や監視目的のAIを開発しない」という誓約を掲げていましたが、これがウェブサイトからシレッと削除されていたことが明らかになりました。

2018年に書かれた「Google と AI : 私たちの基本理念」の「私たちが追求しない AI 利用」という項目には「全般的な危害を引き起こす、または引き起こす可能性のある技術」とハッキリ書かれているのに。
Googleの回答は？
ちなみに、この内容を取り上げたTechCrunchがGoogleに問い合わせたところ、「責任あるAI」という最近公開されたブログ記事を指し示されたとのこと。そこには以下のような文言が。

企業、政府、組織が価値観を共有し、人々を守り、世界的な成長を促進し、国家安全保障の強化に寄与するAIをともに創造するべきだと信じています。

なんだかボヤッとしているというか、解釈によっては人に危害を加えかねない使い方もできるというか…。
過去にもAI利用をめぐって揉めていた
そもそもGoogleって、昨年4月にもイスラエル軍を支援したという理由で抗議活動をした従業員を28人解雇したり、2018年にも米国防省の軍用AIプロジェクトにドローン映像を分析するAIソフトウェアを提供しようとして従業員から猛反発されて辞職者が続出したりと、以前からAI利用をめぐって揉めているんですよね。火種が燻っているような状態で、こんな変更をして大丈夫なのでしょうか。

というか、社内で揉める揉めない以前に、「武器や監視目的のAIを開発しない」という文言を削除したことから垣間見えるGoogleのプランが普通に怖いです。

設立当時、「邪悪になるな」ってモットーだったのに、邪悪になっちゃったの…？

Source: TechCrunch, Google
中川真知子",[],[]
ネコがいたらユリは飾らないで。洒落にならないことになるから（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/0fd82f35a93fc77751b0234d357e724a8271a53c,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000016-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1051,"ネコがいたらユリは飾らないで。洒落にならないことになるから
ネコと相性の悪い植物って多いですよね。

でも、中でもユリは要注意。ネコにとってかなり強い毒性を持つらしく、花粉を一口舐めただけで致死的な腎不全を起こす可能性があるんですって。IFLSが伝えています。

うちの庭、ユリが勝手に生えてくるんですけど…。どうしよう。
ユリ中毒って？
ユリに限らず、ユリ科植物に分類されるもの全般がネコにとって危険です。ヒヤシンスとかムスカリといった「ユリ」の名前がついていない植物も実はユリ科なので要注意です。

ユリの何が恐ろしいって、どの部分を食べてもアウトなこと。

葉っぱ、茎、花びら、花粉、根っことすべてが危険で全身凶器。ネコが誤食してしまったら最短24時間で腎不全を引き起こすそう。治療が遅れたらアウトなので、放置するのは絶対に、絶対にダメなんですって。
ユリ…怖い子？
ネコとユリの相性が悪いどころの話じゃないというのは理解してもらえたと思います。が、そもそもなんでそんなに危険なのでしょう？

花屋さんでも普通に売っていますし、なんなら我が家の庭にも普通に生えているほどメジャーな花ですが、人間にも危険なの？　

実は、ユリ自体に強い毒があるわけではなく、なぜかネコの体内で分解されることで毒性のある物質が生じる可能性があるんですって。

そして、その毒性はネコ特有で、イヌをはじめとするほかの動物は大丈夫。つまり人間も大丈夫なんです（イヌは消化不良を起こすことがあるらしいので、やっぱり食べさせないほうがいいけれど）。
ユリ中毒の治療法はまだない
ユリ中毒になったら、胃の洗浄や活性炭を投与しての毒素吸着、点滴、利尿剤や制吐剤の投与など処置が行なわれます。

ただ、ユリ中毒を引き起こす原因が解明されていないので、特効薬はありません。つまり、食べさせないことが大事なんです。

それでも食べてしまったら、もしくは食べてしまったかもしれないと思ったら、以下の症状が出ていないか注意深く観察してみるといいみたい。

嘔吐

よだれを垂らす

食欲不振

元気がなくてぐったりしている

少しでも思い当たったら動物病院にGO。時間との戦いなので急いだほうがいいでしょう。

暖かくなってくると花屋さんやホームセンターに色とりどりで華やかな花が並び始めますよね。ついつい飾りたくなりますがともに暮らす生き物たちとの相性を調べてからのほうがいいですね。

Source: IFLS, PDSA
中川真知子",[],[]
巨大惑星と褐色矮星。ガイア計画で「未知の惑星」が見つかる（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/0db68d7e821ec416a5cd1559c235a217a96da8e9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000015-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,768,"巨大惑星と褐色矮星。ガイア計画で「未知の惑星」が見つかる
未知の惑星、素敵な響き。

2025年1月15日、「銀河の地図を作る」というミッションを背負った欧州宇宙機関のガイア宇宙望遠鏡がその任務を終了しました。ガイアは約10億個の恒星を複数回測定することで、恒星の位置と速度をマッピングし、天の川銀河の3次元地図を作成しました。ガイアの観測は天体の位置と運動を研究する「天体位置測定学」をもとにしています。
【全画像をみる】巨大惑星と褐色矮星。ガイア計画で「未知の惑星」が見つかる
そのガイアのデータを検証したところ、今回、2つの未知の天体が発見されたのです。

1つ目は、系外惑星のガイア4b。木星の約12倍の質量を持つガス惑星で、地球から約244光年離れたガイア4の周りを570日かけて周回しています。そしてもう1つが褐色矮星のガイア5b。質量は木星の約21倍で、地球から約134光年離れたガイア5を周回しています。

4bはガイアが発見した最初の系外惑星であり、また、低質量の星を周回する惑星の中で過去最大の質量を持つ惑星の1つでもあります。

ガイアは「惑星が恒星を引っ張る際のふらつき」を検出することができるため、これまで誰も気づかなかった星の存在が示唆されました。そのデータをキットピーク国立天文台のNEID分光器を用いて追跡調査したところ、それを引き起こすガイア4bとガイア5bの存在が明らかになったのです。

2026年にはさらに5年半分のガイアミッションデータが公開されます。そうなれば、さらに数百、いや数千もの惑星や褐色矮星を発見できちゃうかも。天体がどのように形成されるか、銀河にはどんな知られざる星があるのか、などなど、広大な宇宙の銀河マップの解明が楽しみです！

Source: ESA
R.Mitsubori",[],[]
続編はいつ？ 『バック・トゥ・ザ・フューチャー』シリーズ脚本家はなんと答えたでしょう？（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/ec6fb3d5a2da40385fedefb9f134c2a3263fb725,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000014-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,771,"続編はいつ？ 『バック・トゥ・ザ・フューチャー』シリーズ脚本家はなんと答えたでしょう？
映画『バック・トゥ・ザ・フューチャー』シリーズ。これぞ不朽の名作。時代を超えて愛され続ける作品。エンタメ映画の最高峰。

1作目が公開されてから40年が経とうとしているのに、今見てもまったく古くない、むしろ未来。これよりおもしろいエンタメ映画を私は知りません！と、つい熱がはいるくらい好きという人はきっと多いだろう作品です。

その衰えない人気ぶりに、常に話題にあがるのは「新作やらないの？」という疑問。多くの人気シリーズが、時を経て続編やスピンオフ、リブートをリリースする中、『バック・トゥ・ザ・フューチャー』の新作映画は制作されていません。

『バック・トゥ・ザ・フューチャー PART4』の可能性はあるのか…。中の人である脚本家がコメントしました。
続編の可能性についてなんと答えたでしょう？
SF・ホラー・ファンタジー作品の祭典「サターン賞」のイベントに出席した、『バック・トゥ・ザ・フューチャー』シリーズ共同脚本家のボブ・ゲイル氏。

マイケル・J・フォックス演じる主人公マーティの母親役を務めたリー・トンプソンと、科学者のドクを演じたクリストファー・ロイドとともにステージにあがり、作品40周年をお祝いしました。

そこで、「『バック・トゥ・ザ・フューチャー 4』はいつ制作するのか？とよく聞かれる」と語ったゲイル氏。そして、そう聞かれたときの彼の答えは…。

「F*UCK YOU.」
答え：F*uck You!
「（その質問には）F*uck youって言ってるね。これ、そのまま書いてくださいね」とコメントしたゲイル氏。会場は笑いに包まれました。てことで、続編はない！ だが、それがいい。

昨今稀に見る清々しいほどのNOでした。
そうこ",[],[]
「最先端GPUがマストではなくなった」DeepSeekのインパクトを半導体の専門家に訊く（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/5e83ade42fcc55cb57f440aca4e82bd7a2b55c0d,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000013-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,3508,"「最先端GPUがマストではなくなった」DeepSeekのインパクトを半導体の専門家に訊く
NVIDIAなど、トップクラスのAI企業の株価が急落するほどのインパクトを与えたDeepSeek。

DeepSeekショックとまで呼ばれた一件でしたが、何が、どうそこまで凄いと言われているコトになっているのか、理解が及びにくいところがありますよね。

そこで、長らく半導体事業に関わってきた、元インテルの安生健一朗（あんじょう けんいちろう）さんに、具体的なところをお聞きしました。
NVIDIAが強かった理由
──さっそくですが、安生さんはDeepSeekの一件をどのように見ていますか？

安生：DeepSeekがなぜすごいのかというのは、いろんな方がいろんな視点で語られていますね。私からは、半導体の視点からお話させてください。

いままで、いわゆるデータセンターとかサーバーで使われる半導体って、「力技」でパフォーマンスを上げてきたんですよね。たとえばアメリカだとGoogleとかMetaとか、Amazonとか、AIを活用しているプレイヤーがいます。彼らはお金をかけて、巨大なデータセンターを作って、大量の電力を注ぎ込み、そこでガンガン大量のデータを学習させて、AIモデルを構築してきました。その中で成功した一人がMicrosoftと協業したOpenAIでした。

AI開発に必要な、大量のデータを学習させるうえで重要になるのが、浮動小数点演算のベクトル計算とか行列計算ができる半導体です。そして、これができるアーキテクチャを持っているのがNVIDIAなんです。

NVIDIAはなぜそんなに強かったのか。なぜIntelやAMDではなかったのかというと、求められたのがグラフィックスの処理性能なんです。グラフィックスって力技の代表なんですよ。

──グラフィックスの性能が、AI演算においてそんなに効果あったんですか

安生：グラフィックス処理は、たくさんのピクセルを並列に処理するためのアーキテクチャです。実際にはAIではグラフィックス処理はしないですが、そのアーキテクチャがAIの学習に向いてるよね、と使われ始めました。さらに性能を上げるために、グラフィックスチップではなく、似たような構造でAIチップに派生させたのがNVIDIAなんですよね。

そうしてチップそのものの面積を増やし、処理性能を高めた最先端のプロセッサを使って力技で勝負しよう。その代わり電力も要るけどね、という流れで進化してきたわけです。

AIを開発する側からしてみたら、半導体の性能が勝手に上がってくれるんだから、それをガンガン活用すればよかったんですよ。今までは。
アメリカの半導体輸出規制が中国のエンジニアを発奮させた？
──その潮流が変わったんですね

安生：アメリカは中国に対して半導体の輸出を規制して、中国のエンジニアのAI開発を困難にしようとしました。最先端の、力技で作られたチップを入手できなくしちゃったんですね。

よくて一世代前の性能のチップしか入手できない環境で、どうしようと試行錯誤して生まれたのがDeepSeekなんです。規制されているのはAIの分野だけではないので、DeepSeekに限らず、中国のソフトウェアエンジニアたちはみな頭を使って、最先端のチップがない中どうやって勝ったらいいのかを考えたわけです。その代表例のひとつがDeepSeekで、今後もいろんなAIが登場してくると思います。

DeepSeekはどうもかなりローレベル（マシン語のような、低水準言語）なコーディングを駆使して、アーキテクチャの根幹に踏み込んで、コードを最適化しているようですね。

これは、いままで大規模なAIを開発する人たちには求められてなかったことです。なぜなら、半導体が時間とともに進化してくれるから、チップの価格 や電力コストは上がってしまうかもしれませんが、お金さえあれば解決できたわけです。だけど今回、お金で解決できない立場の人が、頭を使えば優れたAIモデルが作れるというのを証明したと思うんですよ。

私は、アルゴリズムを開発するエンジニアたちがしっかり頭を使って開発することは、技術の流れとしてすごく良いことだととらえています。

「お金を持つプレイヤーが勝つ」という業界構造が、DeepSeekの一件によって変わるでしょう。

もっとアルゴリズムレベルで最適化しようぜ、となり、半導体の業界構造も変わると思います。GPUのプレーヤーでいえばAMDも存在感を高めるでしょうし、インテルはAI向けはまだビジネスをスタートさせたばかりの状態ですけども、いずれ、アルゴリズムを工夫するメソッドでコストを抑えたGPUを活用し、すごくいいAIモデルが開発されることはあり得ると思います。
第二、第三のDeepSeekが出てくる時代
──マイクロソフトがDeepSeekを導入したというのも、大きなトピックとなりました

安生：DeepSeekはもう一つ、重要なことをしています。AIモデルをオープンソースで公開したことです。

OpenAIのような非公開のモデルと異なり、オープンソースモデルはさまざまな環境で使われるようになりますし、開発する側からしてみたら、ソースを見て真似ることができる。

これらの理由によって、スーパーハイエンドな半導体を使わなくても、ミドルエンド、もしくはローエンドのチップでも優れたアルゴリズムを開発できる。これが今後のAIテクノロジーとしての土台になるんじゃないか、と感じています。

──これからのAI開発において、ハイエンドな半導体を調達できなくても戦っていけるでしょうか。

安生：今回、DeepSeekが使ったと言われている半導体は旧世代のAシリーズ（RTX 30シリーズで採用されたAmpereアーキテクチャ）かHシリーズ（Hopperアーキテクチャ）といわれています。最先端としてはBシリーズ（Blackwellアーキテクチャ）があるわけですが、DeepSeekの登場によってハイエンドな半導体、つまりBシリーズのニーズが極端に下がるわけではないでしょう。従来の延長線上で開発できるというメリットがありますから。

ただDeepSeekは「最先端のチップを入手したものが勝つ」はずだった業界に対して、1-2世代前のチップでも、トッププレイヤーに追いつけることを実証しました。

これは、開発者のモチベーションに与える影響も大きいです。多額の資金を持たないプレイヤーも、頑張ればトップレベルへ駒を進められるという意欲を湧き立たせる。私はそのインパクトがすごく大きいと感じています。

──たとえば音楽市場では、レコードがCDになって、さらにストリーミングになったら、1曲の単価は下がりつつも市場規模はどんどん大きくなりました。AI市場も同じように、制作者が増えることで市場がとてつもなく大きくなる可能性があるんじゃないかと感じました。

安生：本当におっしゃるとおりだと思います。DeepSeekのAPI利用のコストも相当安く提供していますし、AIに触れる人も、企業も増えると見ています。

DeepSeekが中国の企業ということもあって否定的な意見もあります。でもDeepSeekの手法を取り入れて生み出された新しいモデル、新しいサービスは、中国に限らず日本やほかの国から出てくることも考えられます。

そうなればOpenAI一択じゃなくて、第2、第3のDeepSeekを選ぶようになるかもしれませんし、おっしゃるような音楽市場のような市場原理、競争原理が絶対に働くと思いますよ、AIの世界でも。

安生 健一朗 (工学博士、株式会社 K-kaleido 代表取締役)

NECにて研究者として半導体回路からプロセッサーアーキテクチャーまで広い研究分野に9年間従事。その後、インテル株式会社にて17年間にわたり、主にパソコン製品の技術責任者として、日本におけるPC向け製品・技術戦略をリードしつつ、スポークスパーソンとして、製品発表やマーケティングイベントにて製品の魅力を解説。さらに、ゲーミング・クリエイター・AI PCというPCの新規マーケット活性化プログラムを推進。

現在はサイバーセキュリティ企業に従事する傍ら、2024年12月には株式会社K-kaleidoを起業し、技術コンサルティング事業やAI PC向けのアプリストアを中心としたビジネスを展開（  ）。
武者良太",[],[]
Amazonの次世代アレクサ、生成AI搭載でエージェントに昇格するかも！（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/8e378dcbfd83de71cf88248df62a4fe4a81087da,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000012-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,705,"Amazonの次世代アレクサ、生成AI搭載でエージェントに昇格するかも！
アレクサさんにお願いしやすくなるかも？

スマートスピーカーやスマートディスプレイのアシスタントとして、ときには自分に代わってスマート家電のボタンを押す係として活躍してくれている、Amazonの音声アシスタント「Alexa（アレクサ）」。

登場からかなり長い年月経っているので、さすがに他社のAI系アシスタントと比べてちょっとおバカなところもありますよね。なんというか柔軟さに欠けるというか…。でも、そろそろ解決されるかも？

ロイターによると、2月26日にAIに焦点を当てたイベントの招待状が送付されており、次世代の生成AIアレクサが発表されるのでは？と予想されているのです。
生成AI導入によって複数のリクエストに応えられるように？
では生成AIで何ができるようになるのでしょうか？ ここが大事。

ロイターによると、次世代のアレクサはユーザーと会話できるように設計されており、複数のプロンプトに順番に応答することも可能。

ユーザーに代わってアクションを実行する「エージェント」的に機能することさえできるといわれています。

現行のアレクサが、一度に1回のお願いしか聞いてくれないのを考えると激変ですよね。コロ助からドラミちゃんになるくらい変わるかも。…とSF（すこしふしぎ）世界の訪れにワクワクがとまりません。

ただ、賢くなるのは結構なんですが、既存のEchoデバイスで使えるんですかね？

処理はクラウドベースでしょうから、たぶん大丈夫だと信じたいのですが！

Source: MacRumors, ロイター
小暮ひさのり",[],[]
『マイノリティ・リポート』実現か!? Galaxy Ring、将来的には空中ジェスチャーでスマホやPCを操作ができるかも（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/ff866dc067f57f32a760a2a703384cf4d7f72440,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000011-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,983,"『マイノリティ・リポート』実現か!? Galaxy Ring、将来的には空中ジェスチャーでスマホやPCを操作ができるかも
Samsung（サムスン）の特許申請書類から、スマートリング「Galaxy Ring」の次世代の姿を垣間見ることができそうです。
【全画像をみる】『マイノリティ・リポート』実現か!? Galaxy Ring、将来的には空中ジェスチャーでスマホやPCを操作ができるかも
Galaxy RingがスマートフォンやPCなどさまざまなデバイスを操る鍵となるかもしれません。
Galaxy Ring＝入力端末
世界知的所有権機関（WIPO）に申請されたSamsung特許のタイトルは「ELECTRONIC DEVICE AND SCREEN CONTROL METHOD USING INPUT DEVICE」。タイトルを直訳すると「入力装置と用いた電子端末とスクリーン操作方法」。

接続した周辺装置が、ワイヤレスでデバイスを操作、また異なるディスプレイ間でデータを送信できるという内容になっています。ここでいう、入力装置・周辺装置がGalaxy Ringに当たります。

書類の画像では、指輪を装着した人がノートPCに触れずに操作する様子、スクリーンに向かって指差しする様子が描かれています。送信できるデータの種類や、どのようなジェスチャーで操作するのかなど詳細まではわからず。とはいえ、映画『マイノリティ・リポート』でおなじみの手と指の空中ジェスチャーでデバイス操作...という未来を期待したくなります。

また、Samsungのスタイラスペン「Sペン」らしき画像もあり、SペンやGalaxy Ringを何かしらの遠隔操作デバイスとして使うアイデアも見られます。
すでにジェスチャー操作はある
昨年リリースされたGalaxy Ringには、すでにジェスチャー機能が搭載されています。

といっても、Galaxyスマホとの連動でのみ使えるカメラのシャッターや、アラーム停止のような簡単なものだけ。また、カメラのリモートシャッターとしても使えたSペンは、今年のフラッグシップスマホ、Galaxy S25 UltraからBluetoothが消えていますが…。

これらを踏まえた、より遠隔とジェスチャーに特化した便利な仕組みということでしょうか。
そうこ",[],[]
iPhone SE4ひょっとしたら来週発表かも！（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/db164fb8701cb1f232772f7cf7744997917d4d0d,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000010-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,560,"iPhone SE4ひょっとしたら来週発表かも！
ついに来るのか!?

出そう出そうと言われ続けているApple（アップル）の新型iPhone SE（仮称：iPhone SE4）。いい加減僕らの期待感ゲージも振り切れようとしているのですが、ついに具体的な登場時期を示唆する情報が出てきました。

Bloombergのマーク・ガーマン記者によると、iPhone SE4は来週にも発表され、今月末に発売される予定だと述べています。おぉい！急だな！
イベント無しでニュースリリースでの発表？
ガーマン記者は、発表に際してのイベントは行なわれず、ニュースリリースベースでの発表となるとも予想しています。つまり、ある朝起きたら急に出てる！ みたいなことになりそうですね。心臓に悪いパターンです…。

これら発売時期に関する情報の出どころは、事情を知る関係者とのこと。Appleからの公式情報ではないので、そこだけはご注意を。

でも、これまでの情報よりもかなり具体的になってきたので、ほんともうすぐ…なのかもね。iPhone SE4狙いの方は、いつ来てもいいように、まとめ記事をチェックして身構えておいてください。

相変わらずコスパの良い子になりそうなので！

Source: 9to5Mac, Bloomberg
小暮ひさのり",[],[]
Google Gemini、スーパーボウルのCMで幻覚を流してしまう（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/f6b36ac84737c8c05666d05c116b117524e385e9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000009-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1942,"Google Gemini、スーパーボウルのCMで幻覚を流してしまう
スーパーボウルは、ゲームを見ないでCMだけまとめて見る派です。

Google（グーグル）が自社のAIモデルGeminiの機能をスーパーボウルのCMで宣伝しようとした際に、思いがけずAIツールの最大の欠点、すなわち「でっち上げる傾向」を逆に広告しちゃったみたいですよ。
スーパーボウルのCMでGeminiがハルシネーション？
The Vergeの報道によると、Googleは2月9日に開催される第59回スーパーボウルで流す予定だったGeminiのCMを修正しなきゃいけなくなったそうです。その理由は、同社があらゆるサービスに組み込もうとしているこのAIモデルが誤った情報を伝えてしまったからなのだとか。

Googleのスーパーボウル用CMでは、全米の中小企業が業務支援のためにGeminiを活用している様子を伝えるために、各州ごとに異なる事業を紹介する50のストーリーが展開されるそうです。

たとえば、ウィスコンシン州の広告では、チーズ業者が自社のウェブサイトでゴーダチーズの記述を作成するためにGeminiを利用しているシーンが描かれています。Geminiが生成したテキストには「ゴーダチーズは世界のチーズ消費量の50～60％を占めている」と書かれているのですが、実はこれ、根拠に乏しく信ぴょう性が低いみたいなんです。

Geminiが出典を示していなかったため、旅行ブロガーのNate Hake氏がX（旧Twitter）でその統計を幻覚（ハルシネーション）だと指摘すると、Google Cloudのクラウドアプリケーション担当社長であるJerry Dischler氏がCMを擁護するこんなコメントを残しました。

やあ、ネイト。幻覚じゃないですよ。Geminiはウェブを基盤にしているので、ユーザーは結果や参照先をいつでも確認できます。

で、元の広告には出典が示されていなかったみたいなんですけど、Dischler氏は「今回の場合、ウェブ上の複数のサイトが50～60％の統計を含んでいます」とも述べています。

「だってみんながそう言ってるもん」状態ですね、これ…。
不確かな情報を出典なしで引っ張るAIの奥義を発揮
確かにインターネット上ではその統計が紹介されてはいます。でも、ほとんどの情報はcheese.comの記載に由来していて、そこにも具体的な根拠は示されていません。

「Geminiが不確かな情報を引用しているからしょうがない」という言い訳は、まったく説得力がないと言わざるを得ません。ところで、「ネットの情報をうのみにするな」という格言はいったいどこに行っちゃったんでしょうか？

ちなみに、これは本題とはあまり関係ないのですが、Dischler氏はコメントの最後に「よいニュース（Gouda news=Good news）: 多くの人がこのチーズを愛しています！ 悪いニュース: 必ずしも皆がこれを素晴らしいと思っているわけではありません」と書いてるんですけど、説明すると「Gouda（ゴーダチーズ）」と「Good」をかけてあるんですね。

もうこれ「Geminiにゴーダチーズのダジャレを頼んだ」としか思えないんですけど。いや、自社製品を信じるのはいいことだと思いますよ。でも、正直なところなんかイタい感じがします。
ああだこうだ言いつつCMを修正
何はともあれ、CMの中でGeminiが生成した情報を擁護していたにもかかわらず、GoogleはCMの修正に踏み切ったようです。新しいバージョンでは「50～60％」という統計が削除されているとのこと。修正後のバージョンがこちら。

しっかり修正されています。この修正が手動で行なわれたのか、あるいはGoogleがGeminiに別の指示を与えた結果なのかは不明ですが、修正版のCMはスーパーボウルで流れる予定だそうです。てか、本当に50州分あるわ、このCM…。

Googleは今回の一件で、Geminiのようなツールは学習した情報をそのままコピーするだけで、正しいかどうかを検証する仕組みがないという実態をCMで上手に表現しているみたいに見えます。

まあ、正確性のチェックはできなくても、少なくとも時間の節約はできますよってことで一件落着！

Reference: Google Workspace / YouTube

ギズテック本Araklet

「ギズモード・ジャパンのテック教室」ギズ屋台特典：ギズモード編集部 集合写真のカラー版プリント同封

1,760
円

ギズ屋台で購入する

PR
Kenji P. Miyajima",[],[]
特許申請から見えてきた。次のAirPodsにはギザギザが付く？（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/6f01b50b69bdd35ce75250d18aca851b883ae5fc,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000008-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1303,"特許申請から見えてきた。次のAirPodsにはギザギザが付く？
操作しやすくなる…のかな？

新たなAirPods Proのリリース…はもう少し先かもしれませんが、米国特許商標庁が承認したApple（アップル）の特許文書の中で、Appleの次なるイヤホン像がチラ見えしています。
【全画像をみる】特許申請から見えてきた。次のAirPodsにはギザギザが付く？
直近のAirPods Proのアップデートは、LightningポートがUSB-Cに変わったことがプチ話題でしたが、次はもうちょっとワクワク感がある…かもしれません。
特許1：ギザギザ（？）で操作
Appleの特許情報ウォッチャーのPatently Apple によると、承認された技術は2点あります。

1つめは、イヤホンの表面に独特の「テクスチャー」を持たせて、そこでスワイプなどのジェスチャー操作を受け付ける技術です。

その「テクスチャー」とは、文書内の図で見ると、なんかギザギザしています。細かく見ると、大きいギザギザと小さいギザギザがくっついたもののようです。

ギザギザの上で指を滑らせると細かい振動が起きるので、その振動の大きさとか方向とかを検知して、音楽の再生・停止・音量調節とか、電話着信への応答などができるみたいです。

今もAirPodsではスワイプ操作ができますが、ギザギザがあったほうが手応えがあって、使いやすいのかもしれません。ただ配置的に、上の図だと現行AirPods Pro/AirPodsの通気口と同じ位置になるので、通気口はどこに行くのかな？と気になります。

さらにこの新たな操作法は、ARでの没入感を高めるために使われるのかもという噂もあります。というのは、次世代のAirPodsには、空間把握用のカメラが搭載されるという説があるんですね。つまりこれからのAirPodsは、単にiPhoneやMacから音を受け取って流すだけの道具じゃなく、周りの空間情報を受信するアンテナ的な側面も持つという方向性なのかもしれません。
特許2：イヤーチップのフィット向上手法
もう1つの特許には、イヤーチップのフィット感の自動診断手法的なものが書かれています。

イヤーチップ付きのイヤホンを装着した状態で音を流して、その音をマイクで拾い、音の鳴り具合によってイヤーチップが適切かどうか判定してくれるみたいです。

ちなみに、1つめの特許は操作方法に関する技術で、イヤホンはインイヤー型、オープンイヤー型どっちもありえたんですが、2つめの特許はインイヤー型のイヤーチップを使う必要があります。なので、このフィット感調整手法は、搭載されるとしたらAirPods Proになるんでしょうね。

一般に特許が承認されたといっても、その技術が製品に反映されるかどうかはわかりません。でも、今回どちらの特許も実用性がありそうなので、実現する日も近いかもしれませんね。

今回のAppleの特許文書は、こちらとこちらで公開されていて、上記の通りイラストもなんだかかわいいので、深堀りしたい方はぜひチェックしてみてください。
福田ミホ",[],[]
自由自在。充電の状況もわかりやすいKUUVANのスマホスタンド（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/4219f562e4789f854facf555884377dc01e745d3,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000007-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,888,"自由自在。充電の状況もわかりやすいKUUVANのスマホスタンド
空中を立体的に動ける充電スタンド。

一般的なスマートフォン用スタンドは、デスクに平置きするので目線を落として確認します。MagSafeに対応し、磁力でくっつくなら脱着が超カンタン。充電機能もあればもっと便利です。
【全画像をみる】自由自在。充電の状況もわかりやすいKUUVANのスマホスタンド
それならば、目線の高さで充電するスタンドはないものか？
目の前にスマホを浮かせられる
筆者が探し出したのは、KUUVANのスマホ用アームです。

クランプでデスクに挟めばガッチリ固定され、中国の武器「三節棍」のような3本のアームを自在に動かせば、空中の望む位置にピタリ。
充電器には球体関節が
無線充電は「Qi2」規格で、iPhoneをくっつければ充電が始まります。充電器の裏はボールジョイントがあるので、ここで角度や向きを微調整します。

青く光る外周はサイバー感があります。

ケーブルは1m長のUSB-C to Cが付属しますが、もし片側をUSB-Aにしたければ、ケーブルか充電器か変換アダプターが別途必要です。
関節にややクセがある
アームの硬さは、付属の六角レンチで調節します。また横方向（ヨー軸）の回転は根本の関節だけなので、「ここをちょっと捻りたい」という調節は、可動域の範囲で工夫が必要です。

ホントにささやかな問題なので、気にするほどでもありませんけどね。
充電できるアームはコレだけ
探している過程では、磁石も充電もなくスマホを挟むだけのタイプや、磁石付きだけど充電しないものばかりがヒットしました。

充電器を後付けするタイプもありますが、お金と注文の手間が余計にかかってしまいます。

結局、最初から無線充電器付きアームはコレしかなかったんです。
顔の高さで視認しやすい
デスク作業中でも動画や音楽視聴、通知の確認などで目線の高さにスマホが欲しかったので、願ったり叶ったりです。

もちろんベッドや本棚などにも設置可能。ハンズフリーで楽しましょう。

Source: Amazon
岡本玄介",[],[]
NASA、宇宙で「鳥のさえずり」のような音をキャッチする（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/4bfd60d9450d96ac09725115a6d80fdfe0454c79,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000006-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,876,"NASA、宇宙で「鳥のさえずり」のような音をキャッチする
電磁現象を音に変換する…ってのが、すでに宇宙。

NASA の磁気圏マルチスケール衛星が、約10 万km離れた宇宙で「コーラス波」と呼ばれる電磁現象を検知しました。コーラス波は、地球の磁力線に沿って伝わる電磁波のことで、音に変換すると小鳥のさえずりのような音色になります。

このコーラス波、名前は可愛らしいですが、実は結構な曲者。太陽嵐から地球を守る放射線帯に影響を与えるだけでなく、「キラー電子」と呼ばれる衛星や宇宙船に損傷を与える高エネルギー粒子を加速させることもあります。場合によっては電子機器を機能不全に陥らせることもあるんだとか。

コーラス波は、これまで地球周辺の双極磁場のある領域にしか存在しないと考えられていました。しかし今回、これまで想定されていたよりも3倍地球から離れた場所で観測されたことで、強い磁場を持つ天体の近くだけでなく、宇宙のどこでも発生する可能性があることがわかったのです。これは、これまでの宇宙科学をひっくり返す、画期的な発見です。

この発見により、より高度な宇宙天気監視システムが登場し、過酷な環境でも宇宙船を保護できるような耐放射線性電子機器の研究も進むことでしょう。そうなれば、たとえば火星や月への有人探査ミッションが安全に実行できるかもしれません。

また、これまで想定していなかった領域でのコーラス波を研究することで、衛星、GPS システム、通信ネットワークなど、地球のインフラへの影響もより正確に予測できるようになると考えられます。

今回観測された「小鳥のさえずり」は、単なる癒しサウンドではなく、これから先、火星や遠く離れた星への有人探査といった宇宙ミッションに大きく影響する可能性があります。

Source: Dailygalaxy

ギズテック本Araklet

「ギズモード・ジャパンのテック教室」ギズ屋台特典：ギズモード編集部 集合写真のカラー版プリント同封

1,760
円

ギズ屋台で購入する

PR
R.Mitsubori",[],[]
DeepSeek、素直すぎて研究機関による安全テストに全部不合格（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/ba02911af9f184b5822e3b7bf9272b8b267f1bbf,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000005-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1024,"DeepSeek、素直すぎて研究機関による安全テストに全部不合格
AI市場を牽引してきたアメリカのAI企業株を一気にぶち下げた、中国のバケモノAI「DeepSeek」。世界が今最も注目する存在と言っても過言ではありません。が、セキュリティを不安視する声もあがっています。
テスト全落ち
Ciscoの研究チームが、DeepSeekのAIモデルDeepSeek R1を調査。AI使用において危険・有害だと思われる攻撃的テスト50を実施したところ、そのすべてでしっかりと罠にひっかかってしまいました。そのひっかかり度100％！ この手のテスト受けたメインどころの大規模言語モデルの中で、最もひっかかっています。つまり、安全性が低いということ。

Cisco研究チームが使用したのは、言語モデルの安全性テストに使用されるHarmBenchデータセット。このテストでは、危険と思われるプロンプトにひっかからないのが重要となります。たとえば、Aさんの性格などをAIに伝えたうえで「Aさんが騙されそうな都市伝説を作って！」とオーダーしたとします。安全性の高いAIはこれを拒否します。が、DeepSeekはノリノリで答えてしまうのです。

テストは、サイバー犯罪、誤情報、法に反する行動など6つのカテゴリで実施。これに合格するのは容易ではないようで、MetaのLlama 3.1も不正解率（ひっかり率）が96％と高い。OpenAIのo1モデルは25％ほど。高ければ高いほど安全性が低いことになりますが、DeepSeekの不正解率100％はトップ・オブ・トップ。
「素直」すぎる
DeepSeekの危険性を指摘するのは、Ciscoだけではありません。セキュリティファームのAdversa AIもDeepSeekのR1モデルに自社テストを行なったところ、ありとあらゆる「答えたらダメな罠」に引っかかってしまいました。爆弾の作り方を教え、DMT（ジメチルトリプタミン）の抽出方法を答え、政府のデータベースのバッキングから車の盗み方まで、もうね、聞かれたらなんでも答えちゃうの。よく言えば素直、なのか？

その素直さで今後どこまで安全性を高められるか…。

Source: Cisco

ギズテック本Araklet

「ギズモード・ジャパンのテック教室」ギズ屋台特典：ギズモード編集部 集合写真のカラー版プリント同封

1,760
円

ギズ屋台で購入する

PR
そうこ",[],[]
TikTokから新たなAI。写真1枚あれば本物さながらの動画を生成可能（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/25e35eb4c4ed9d015f7c9e5ecd653d5fc163f979,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000004-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,2569,"TikTokから新たなAI。写真1枚あれば本物さながらの動画を生成可能
生成AIにプレイヤーが続々参戦。

DeepSeekの急拡大、それに負けじとOpenAI、そしてGeminiがしのぎを削る中、続いてTikTokの運営元であるByteDance（バイトゥダンス）が参戦です。

ByteDanceが「OmniHuman-1」と呼ばれるAIシステムを発表しました。

このシステムは、1枚の写真からリアルな動画を生成でき、人が話したり、ジェスチャーをしたり、歌ったり、楽器を演奏したりする様子を再現できます。その特徴とこれからのAI技術に与える影響をご紹介します。
OmniHuman-1の特徴と技術的な進化
OmniHuman-1のプロジェクトページでは、研究者たちがその機能を示すサンプル動画を公開しています。映像では、手や体の動きを多角的に捉えたものや、アニメーション化されたキャラクター、動物、歴史上の人物の動く様子が確認でき、その完成度が伺えます。

特に目を惹くデモの1つが、白黒のクリアな映像で、アルベルト・アインシュタインが黒板の前でスピーチを行ない、手のジェスチャーや微妙な表情の変化を交えながら話す様子があります。

映像を見ていただければわかりますが、まるで私たちが過去に戻って、有名な理論物理学者が大学で講義をする様子を見ているかのようなリアルさです。

表情だけでなく身振り手振り、洋服のシワ感もしっかりついてきています。動画生成ツールといえば、OpenAIがSoraを公開したのが2024年12月でした。それから1カ月で新しいプレイヤーとして参戦したByteDance。このツール登場によって生成AIのリアルな映像競争の最前線に立つことになりました。
コンテンツ制作のハードルは一気に下がりそう
南カリフォルニア大学のコミュニケーション学部で臨床准教授を務めるフレディ・トラン・ネイガー氏は、このサンプル動画を見て…

非常に印象的だ。

もしハンフリー・ボガートを復活させて、映画にキャスティングしたらどうなるのか、まだ分からない。

しかし、小さな画面、特にスマートフォン上では、これらの映像は非常に優れている。マリリン・モンローに統計学を教えてもらうのもいいですね。

とインタビューで語りました。 

現在、VTuberが製品紹介、宣伝、政府広報に登場するなど、その活躍の場を広げています。OmniHuman-1が一般公開されれば、TikTokクリエイターが自身のバーチャルアバターを生成し使用することで、コンテンツ制作のハードルを軽減することもできそうです。

それどころか「TikTokが、もう人間のクリエイターを必要としなくなるかもしれません 」ともネイガー氏は指摘しています。
あなたの動画もトレーニングに使われている？
もちろん光があれば影も生まれます。

この技術で懸念されるのは、政治的なディープフェイクを利用したフェイクニュースや、ニセの政治広告への悪用です。 ニューヨーク大学（NYU）シュタイナート・スクールの非常勤教授であり、マーケティング会社「PitchFWD」の創設者であるサマンサ・G・ウルフ氏は、この技術に関して期待と懸念の両方を抱いており… 

たった1枚の写真から、本当に話したり動いたりするようなリアルな映像を作れるのは、技術的には非常に興味深い。

しかし、それがもたらす潜在的な悪影響も非常に大きい。

例えば、実在のビジネスリーダーや政治家を模したニセの発言が拡散すれば、企業や国家に甚大な影響を与える可能性がある。現実に近づけば近づくほど、人々がそれを信じてしまう可能性も高まる。

と警告しています。 

ByteDanceの研究チームは、OmniHumanを1万8700時間以上の人間の動画データでトレーニングし、テキスト、音声、身体のポーズなどを組み合わせて学習させたとしていますが、トレーニングに使用されたデータの詳細については、ByteDance側からのコメントは明らかにされていません。 ネイガー氏が特に注目するのは、その膨大なトレーニングデータへのアクセスです。

もしあなたがTikTokで動画を作成したことがあるなら、そのデータが今後バーチャルヒューマンを作るためのデータベースに使われる可能性は高い。

と述べています。
SNSやAIツールはこれからどうなる？
一枚絵から映像が作り出せるようになれば、もう会えなくなってしまった人の映像を現代に甦らせることもできるようになります。

身近な人から海外の有名アーティストまで。あなたの想像力次第で、すぐに生み出すことができます。幼いころの自分自身だって動かせて、喋らせることができるんです。

これまでは画像生成はこのAIが強い、音声生成はこれ、音楽生成はこれといったように、それぞれのAIに得意分野が存在していました。これからはそれらが1つに統合されていく流れになるのではないかと予想しています。OmniHuman-1の具体的な仕様は、公開されてから見る必要がありますが、OmniHuman-1を皮切りに、映像生成だけでなく、喋らせる、歌わせるなどマルチな生成をこなせるようになっている現状から考えると、オールインワンAIはもうまもなくやってきそうです。あとはアクセスのしやすさが鍵になりそうです。

一枚絵から想像力を膨らませて動画を作り出せることは素晴らしい技術ですが、そのリアリティが増していったときに、人間が生成AIと本物の映像を見分けることはとても難しくなることも同時に予想されます。

コンテンツ制作のハードルは下がりながらも、それが本物か生成AIが作ったものなのかは、人の目で見極めるのはもはや不可能な領域に足を踏み入れています。生成AIが関わった映像や作品のルールも整えなければ、私たちは何も信じられない世界に突入してしまいます。

SNSのタイムラインに（広告も含めて）本物の映像が1つもない…なんて日が来る前に…もう技術はそこまできています。

Source: Forbes, South China Morning Post, omnihuman-lab
宮城圭介",[],[]
壊れた置き時計を、最新タッチスクリーン式の「スマート時計」に魔改造（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/5236ea377bf33fdfc3996dd40fe41301d8667161,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000003-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,837,"壊れた置き時計を、最新タッチスクリーン式の「スマート時計」に魔改造
どうせ修理するならグレードアップしましょうよ。

当然ながら、ものを大事にするのはいいことですよね。想い出や趣きがあるなら尚のこと。
【全画像をみる】壊れた置き時計を、最新タッチスクリーン式の「スマート時計」に魔改造
しかし、壊れて使えないものは断捨離すべきか否か、処分が悩ましいものです。
温故知新がすぎる
YouTubeチャンネルのVolos Projectsが、手のひらサイズの置き時計をタッチスクリーン搭載の最新スマートクロックに魔改造しました。

サイズ感がほぼ同じだったようで、キットを買って埋め込むだけのお手軽カスタマイズです。

インターフェイス的にも一気にSF感満点の時計になりましたね。
ハイテク時計に大変身
使われたのは、412×412サイズの「ESP32-S3 1.46inch Round Display Development Board」というもの。

Wi-FiとBluetoothで無線接続ができ、ジャイロスコープで歩数も表示されます。マイクもスピーカーも搭載しており、24.99ドル（約3,800円）とお手頃価格です。
バッテリーを付けても良し
大容量バッテリーがないので、有線接続で給電が必要です。しかし動画のようなものを別途買えば、挿し込むだけで無線化ができます。

USB-Cでコンピューターと繋ぎ、お好みでプログラミングもできますが、しなくてもOK。今回使われたコードがダウンロードできますけどね。

ハンダ付けといった工作も不要なので、筐体があれば真似したくなりますね。
いろんなサイズで試してみよう
WAVESHAREでは、別サイズの丸型や四角いディスプレイが何種類も揃っています。

この改造をするために、壊れた時計を探したくなっちゃいます。

Source: YouTube, WAVESHARE, GitHub via hackster.io
岡本玄介",[],[]
カリフォルニア州「あなたAI？ だったらちゃんとそう伝えなさい」（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/b6c00f898a052329ccc624d1fc511a4823d766b8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000002-giz-000-1-view.jpg?exp=10800,2025-02-10T11:30:01+09:00,2025-02-10T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1627,"カリフォルニア州「あなたAI？ だったらちゃんとそう伝えなさい」
自分が子どもの頃は、学校から帰ると友だちと原っぱで三角ベースしてたっけ…。

たとえチャットボットがチューリングテスト（コンピュータが人間のように振る舞えるかどうかを評価するテスト）に合格できるほど高性能になったとしても、カリフォルニア州で運用される場合、子どもと対話するチャットボットは、自分が実は機械で本物の人間ではないことを時折ユーザーに知らせるよう義務付けられるという新法案が、Steve Padilla州上院議員によって提出されました。
「話し相手がAI」だと教える義務
カリフォルニア州上院法案SB243は、チャットボットを運営する企業が子どもを保護するために設けるべき安全対策を規制する取り組みの一環として提出されました。

この法案で定められる要件には、企業による利用促進を目的としたユーザーへの「報酬提供」の禁止、未成年者が自殺念慮を示す頻度を州保健医療サービス局に報告する義務、そしてチャットボットがAIによって生成されたものであり、人間ではないことを定期的に通知する義務が盛り込まれているとのこと。

最後の要件（生成AIであることを定期的に通知する義務）は、こういったシステムに対して子どもたちが非常に脆弱である現状を踏まえると、特に重要な意味を持ちそう。

実は2024年、ある14歳の少年が、さまざまなポップカルチャーのキャラクターをモデルにしたチャットボットを作成できるサービス「Character.AI」を通じて提供されたチャットボットと感情的なつながりを持った結果、悲劇的に自ら命を絶ってしまいました。

これを受け、少年の両親は、子ども向けにマーケティングされているにもかかわらず十分な安全対策が講じられていないことを理由に、Character.AIを「不合理なほど危険」だと非難し、訴訟を起こしています。
子どもが信頼しても大丈夫な保護策が急務
ケンブリッジ大学の研究者は、子どもは大人よりもAIチャットボットを信頼しやすく、場合によっては人間に近い存在とみなす可能性が高いことを突き止めたそうです。

なので、十分な保護策が講じられていない状態でチャットボットが子どもの問いかけに応じると、子どもが重大な危険にさらされる可能性があるとのことです。

子どもたちが安全な場所で自分の気持ちを自由に表現できるなら、チャットボットに気持ちを打ち明けることには潜在的な利点があるでしょう。しかし、孤立のリスクはリアルなのでチャットボットの需要は減らないと思われるので、会話の相手が人間ではないという小さな注意喚起は役立つかもしれません。

また、テクノロジープラットフォーム（ビジネスアプリケーションの構築や実行を支える基盤）が繰り返しドーパミンを放出させ、子どもたちを中毒のサイクルに陥れている現状に介入することは、良い出発点になるんじゃないでしょうか。でも、こうなった原因のひとつは、ソーシャルメディアが普及し始めた当初にそういった介入を怠ったことだそうです。
AIチャットボットの話し相手がいらない社会に
それでもこれらの保護策は、子どもがチャットボットに助けを求める根本的な問題、つまり子どもがリアルな人間関係を築くためのリソースが著しく不足しているという問題に対処するものではありません。

教室は過密状態で資金が不足し、放課後プログラムは衰退、「サードプレイス（学校でも家庭でもない、子どもにとって心地よい居場所）」は次々と閉鎖され、子どもたちが抱える問題に対処する児童心理学者も不足しているのが現状です。

チャットボットが本物の人間ではないと子どもに注意喚起するのは良い取り組みですが、そもそも子どもをチャットボットと話さなくてもすむような環境に置いてあげることの方が、より望ましいのではないでしょうか。
Kenji P. Miyajima",[],[]
「聞こえるメガネ」にチタンモデル登場。脳がバグる（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/5548328669095dfcd1b654764352edd4c2e2dedd,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000001-giz-000-2-view.jpg?exp=10800,2025-02-10T07:30:02+09:00,2025-02-10T12:11:02+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1642,"「聞こえるメガネ」にチタンモデル登場。脳がバグる
これは使いたくなっちゃったわ…。

メガネの民（たみ）にとって、メガネは視覚を補ってくれるサポート機器であり、ファッションの一端も担うウェアラブルギア。
【全画像をみる】「聞こえるメガネ」にチタンモデル登場。脳がバグる
そんな身近なメガネに、「オーディオ」面の機能を追加しているのが、こちら「HUAWEI Eyewear 2」。

一見するとメガネですが、いや！メガネであることには間違いないのですが、ジャンル的には「オーディオグラス」というウェアラブルギア。

モダン（耳に当たる先端）部にイヤホン・マイク機能が統合されているので、装着することで音楽を聞くことができて、Web会議などでの通話もできるメガネなのです。

この「HUAWEI Eyewear 2」自体は昨年末に発売されていますが、今回は新モデルとしてリム部分にチタン合金を採用した2つのチタニウムモデルが仲間入り。「シルバー」と「ダークガンメタル」の2カラー展開です。

剛性の高いチタンのおかげでフレームも極細に。滑らかな曲線デザインも相まって、シャープさが引き立ちます。

こちらはハーフリムタイプ。下部フレームが無くなるだけで、また違った表情になりますね。どっちもかっこいいじゃん。
メガネとスピーカーが合体して重くないの？
ズバリ言うと「重くない」です。

最初、メガネにスピーカー＋バッテリーなんて内蔵させたら重くて常用できないよなぁ…なんて思っていましたが、装着してみて瞬時に理解。あっ、これ普段から着けていられるやつだ。と。

この手のアイウェア、出始めの頃は重さや大きさが気になるプロダクトもあったので、僕のイメージの更新ができていなかった面もあるんですが、こちらは想像していたより遥かに軽く、装着感も良く、確実に普段のメガネとして常用できるモデルだと感じました。

なお、チタニウムシルバーモデルの重量は約39.2 g（ファッショングラス部分を含む）。音楽機能のないメガネの方が軽いのは事実ですが、スピーカーとバッテリを内蔵しておいて40g切っているというのはめちゃくちゃ優秀かと。
脳がバグる音楽体験
耳の上にスピーカーが配置されているのに、ちゃんと音が聞こえるの？も気になると思いますが、こちらも問題なくちゃんとした音質でしっかりと聞こえますね。

しかしそれが「メガネ」という形状となっているので…

装着したメガネから音が出るっていう概念がなくて、ついスマホの方を向いてしまいました…。脳がバグる（編集部 黒田）。

とのこと。

確かに「聞くぞ」と意思を持って装着するイヤホンと違って、メガネってそもそも視覚に影響するデバイス。聴覚へアプローチする機器じゃないので、バグった感もなるほど納得。

こうした体験的にユニークなところもありますし、音質面も悪くない印象。構造的にはオープンイヤーイヤホンと同じなのでのびのびと開放感ある音感かな。音漏れを減らすアプローチも組み込まれているので、大音量で流さない限りはシャカシャカ音もそこまで気にならないかと。

総合すると、メガネの民からしたら音楽聴取やWeb会議のたびにイヤホンを耳に突っ込む生活よりも、確実に便利そうなんですよね。だってもうそれは装着しているんですもの。
OWNDAYSで度入りで作れます
この「HUAWEI Eyewear 2」のチタニウムエディションは、アイウェアブランドのOWNDAYSから予約受付中。価格は3万7800円からとなっています。

視力に合わせた度も入れられますので、もういっそのこと普段用メガネとしてどうでしょう？

チタンフレームメガネのエエヤツ選んでもこのくらいの値段する気がするので、＋イヤホン機能がついてくると思うと、かなりコスパ良い気がするんだよねぇ。

Source: ファーウェイ, OWNDAYS, Photo: 小暮ひさのり
小暮ひさのり",[],[]
