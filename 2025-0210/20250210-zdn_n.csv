headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
電子版「薔薇族」、Amazonで販売中止　「ポリシーにそぐわない」とアカウント即時停止に（ITmedia NEWS）,https://news.yahoo.co.jp/articles/2ae182b849c5937373cd168835c724ba17804de2,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000108-zdn_n-000-1-view.jpg?exp=10800,2025-02-10T21:25:09+09:00,2025-02-10T21:25:09+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,513,"（出典：いらすとや）
日本のゲイ雑誌の草分け「薔薇族」の電子版が、AmazonのKindleストアから排除された。同誌の初代編集長でバックナンバーの電子化を手がけていた伊藤文學さんが2月8日にXで公表した。
【画像】「薔薇族」バックナンバーの電子版を販売していたKindleストアのページ（出典：Amazon）
伊藤さんのポストによると「ここにきて、薔薇族がKindleのポリシーにそぐわないということで、アカウントが即時停止となってしまった」という。問い合わせても「強いアダルトは禁止です」という簡単な回答のみで、具体的な説明はなかった。

「これだけ多様性とうたわれているなか、結局はこれなのかという徒労感にさいなまれる。Amazonはグローバル企業だからこそ大丈夫じゃないかという期待はあった。しかしそうではなかったようだ」（伊藤さんのポストより）。今後は新しい配信場所を探す考え。

　薔薇族は、1971年創刊の男性同性愛者向け雑誌。伊藤さんは、創刊時から3度の休刊と4度の復刊を経て2011年7月まで編集長を務めた。24年7月からは電子書籍化したバックナンバーをAmazonで配信していた。
ITmedia NEWS",[],[]
「モンハンワイルズ」、オープンβテスト2週目を24時間延長　PSNの障害受け（ITmedia NEWS）,https://news.yahoo.co.jp/articles/ac922f35e119e9922f925e4dd6c34fef19b56e06,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000107-zdn_n-000-1-view.jpg?exp=10800,2025-02-10T20:23:20+09:00,2025-02-10T20:23:20+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,481,"「モンスターハンターワイルズ」(C) CAPCOM（出典：カプコン）
カプコンは2月10日、「モンスターハンターワイルズ」のオープンβテストについて、2月14日から予定している2週目の開催期間を24時間延長すると発表した。全プラットフォームが対象となる。
【画像】オープンβテストの延長を告知する画像
2月8日に発生した「PlayStation Network」（PSN）の障害により、開催期間が大きく削られてしまったため。延長後の終了時間は、2月18日の午後11時59分となる。

　対象プラットフォームはPlayStation 5の他、Xbox Series X|S、Steam。延長期間においても、製品版で入手できる「参加特典」の受け取り資格を獲得できるという。

　PSNの障害が発生したのは8日（土）の朝。SIEは「PlayStation Storeを含むPlayStation Networkが利用できない場合がある」とX上で報告し、ユーザーにしばらく待つように伝えたが、復旧のアナウンスがあったのは9日午前9時5分だった。
ITmedia NEWS",[],[]
映像編集の“面倒くさい”をどんどんAIに　Premiere Pro β版に搭載された、2つの新機能を試す（ITmedia NEWS）,https://news.yahoo.co.jp/articles/be5834f4bcf169b36f35441e9c44a4e83dcb81eb,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000090-zdn_n-000-2-view.jpg?exp=10800,2025-02-10T16:31:49+09:00,2025-02-10T16:57:04+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,3814,"（写真：ITmedia NEWS）
2025年最初のニュースとして、AdobeはPremiere Pro、After Effectsのβ版およびFrame.ioの新機能を発表した。以前からAdobeは、映像制作ワークローにおけるAIの活用事例をPremiere Proに集約させており、24年には今後実装予定の機能を3つ発表している。そのうち「カットの続きを作る」機能は昨年のうちに実装された。
【画像を見る】「あの映像どこだっけ～」を解決する、テキストで検索できる機能（全10枚）
残る「Bロールを生成する」機能は24年11月のInter BEEの際に実動デモを、「不要なオブジェクトを消す」については、「不要なオブジェクトを自動で切り出す」ところまでの実動デモを拝見した。この1月に公開された25.20β（ビルド97）に実装されたAI関連機能はそのどちらでもないが、ユーザーからリクエストが多かった機能を先に実装したようだ。

　今回は実際にこのβ版に搭載された機能を試しながら、今後の映像制作への変化について考えてみたい。
素材を分析し、検索可能にする「メディアインテリジェンス」
かつて編集者が映像編集を行う際には、素材全てに目を通し、メモを取る。昔はノートにカットのタイムコードとカットの概要、すなわち何が写っているか、1ショットなのがグループショットなのか、サイズはバストサイズなのか、カメラはどちらにパンするのかなどを書き込んでいた。

　それを元に、ポスト・イットにカットの特徴を書き出し、壁に貼り付けて分類、グループ化し、関係性を把握したのち、番組の構成に沿って並び替える。いわゆる文化人類学のフィールドワークで用いられるKJ法をそのまま活用して、編集案を錬っていたわけだ。30分番組でも収録素材はその20倍ぐらいあるので、約10時間。メモを取りながら素材を全部見るだけで3日ぐらいかかる。

　今でもそんなやり方をしている現場は少ないだろう。なぜならば多くの映像制作の現場で、撮影者と編集者が同じになってしまったからだ。これにより映像制作のスピードは格段に向上し、映像は小規模量産体制が整った。自分で撮影した映像をじっくりもう一度メモを取りがら見るというのは、ニュース特集やドキュメンタリーのように、自分が撮ったものがどういう意味を持つのか再考する必要があるコンテンツの場合ぐらいである。

　とはいえ、撮影班が複数あるような大掛かりなプロジェクトでは、編集者が知らない素材が大量にあるという事になる。もちろん、こうした場合は昔ながらのKJ法は有効だが、今はとにかく手を動かして、早速作り始めてしまう編集者も多い。

　こうした手法で厄介なのは、使いたいカットがあるはずなのに見つからないことだ。現代の編集において、カットの存在はビン上にあるクリップのサムネイルから想起されるので、使いたいカットのイメージとサムネイルが全然違っている場合、見つけられなくなるということは起こりうる。仕方なく構成を変えて編集したら、ほとんど出来上がってから使いたいカットが見つかる。そうなると、それを入れるためには構成を変えなければならなくなる。

　こうしたトラブルを避けるために、編集者は素材ビンの中でフォルダを作って分類したり、サムネイルカラーを分けたりしてなんとか区別を付けようとしてきたわけだが、もっともシンプルな解は、「検索して見つかれば良い」というものだ。

　そのためには何らかのメタデータが必要になるわけで、大規模なプロジェクトの場合、素材を見ながらクリップにメタデータを入力していくという工程が発生する。実際に映画等ではこうしたワークフローになっているが、そうしたことをAIでやれないか、というニーズが出てくるのは、当然である。

　今回のPremiere Pro 25.20βで追加されたAI関連の機能の一つが、それである。「メディアインテリジェンス」と名付けられた機能は、プロジェクト内に読み込まれた素材、あるいは新たにインジェストする素材に対して、AIによる分析をかける。

　AIは、それぞれの素材に何が写っているのか、どんなアングルか、何色が含まれているかといった情報を読み取り、メタデータとしてプロジェクトインデックスに記録する。

　編集者は欲しいカットが見つからない場合、テキスト検索によって素材を見つけ出すことができる。入力するのは、画像生成AIに入力するプロンプトと変わりない。何が写っているか、どういうアングルか、昼か夜か、といった条件で検索できる。

　現時点では、日本語のプロンプトには対応していない。だが英単語で入力すれば、検索できる。複数の単語を連ねれば、絞り込みもできる。

　最終的には、解像度やフレームレート、データがあればカメラ名や絞り値など、技術的メタデータも併用して検索できるようになるだろう。技術パラメータは撮影時にカメラ側で記録していないとどうにもならないが、これまで編集時にはあまり活用できていなかったのは事実だ。ただ、現時点ではメタデータ検索はそれほど正確ではなく、該当しないものも引っ掛かってくる。このあたりは検索書式が明確化されれば精度は上がってくるだろう。

　現時点では、Premiere Proに組み込まれた機能ゆえに、プロジェクトに読み込ませた素材しか解析の対象にならず、解析情報はプロジェクトファイルのキャッシュか、素材ファイルと同じフォルダ内のサイドカーファイルに記録するかの選択になる。将来的に期待したいのは、これが別ツールになり、素材を記録したHDDやSSDなどの中身をいっぺんに解析してメタデータ化してくれることだ。具体的には、「Adobe Bridge」のようなアセットマネジャーにこそ搭載すべきである。

　こうした機能は放送局向けのアーカイブシステムではすでに存在するが、個人やプロジェクト単位、小規模プロダクションで利用できるようなものではない。

　さらにAI解析によるメタデータの持ち方が標準化されれば、一度解析したクリップならどの編集ツールでも、あるいは素材ブラウザのような別ツールでも検索が可能になるだろう。これがその第一歩であることを期待したい。
他言語翻訳可能になった字幕
今やAIによる文字起こしは一般的なツールとなり、議事録作成やインタビュー起こしなどに活用されている。昨今では大学の講義を録音してAIで文字起こしし、そのテキストをさらにAIに食わせてサマリーを作らせることで学習を効率化するといったことまで行われるようになった。これに関しては賛否あるところである。

　編集ツールに文字起こし機能を搭載したのは、Premiere Proがかなり早かった。書き起こしたデータを元に、いわゆる「字幕」も入れられる。さらに書き起こしたテキストを切った貼ったするだけで、動画編集ができる機能も搭載した。もともとそうした機能は、韓国の編集ツール「Vrew」が搭載していた機能である。

　今回の25.20βで搭載された新機能に、「キャプションの翻訳」がある。字幕として作成した言語に対して、別の言語に翻訳した字幕を作成できる機能だ。例えば元の言語が日本語だったとしても、英語や中国語の字幕を作成することができる。

　日本語というのは英語、スペイン語、中国語などと違い、世界でそのまま通用するわけではないので、こうした翻訳字幕が作成できれば、コンテンツを世界に発信することもできるようになる。

　とはいえ、製作者が理解できない言語に対しては、その字幕が正しいのか判断ができない。そこが単純に喜べないところである。元のテキストと翻訳テキストを何らかの形で出力し、別のAIで整合性をチェックするといったことは必要になるだろう。いわゆるセカンドオピニオンとして、外部のAIとなんらかの形でインタフェースする仕掛けが、今後は必要になるのではないだろうか。あるいは翻訳エンジンだけ外部のAIを使いたいといった要望も出てくるだろう。

　以前ご紹介した「Captions」というアプリでは、翻訳結果を字幕ではなく、音声で吹き替えてくれるという機能を持っている。だがこの機能は翻訳が間違っていた場合、フェイク動画化してしまう可能性を排除できない。

　AdobeのAIツールは、クリエイターの置き換えを目指しておらず、クリエイターの生産性向上のためだけにAIを使うというポリシーを掲げている。しかしながら、クリエイティブ業界の巨人であり、強い影響力を持つAdobeのこうしたポリシーにもかかわらず、ビジネスの現場では別のAIツールにより、「AIがクリエイターの仕事を奪う」という現象がすでに起こり始めている。本来ならデザイナーやイラストレーターに発注していた仕事を、AIが取って代わるようになり始めているのは事実だ。

　2月13日には、日本でAdobe Max Japanが開催される。ここでもいくつかのAI関連の新機能が披露されるだろう。クリエイターはAIによるワークフロー改革を受け入れながら、AIに取って代われないようなクリエイティブワークとは一体なんなのか、生き残る道を探す必要に迫られている。
ITmedia NEWS",[],[]
「ミャクミャク」深夜アニメになる　NHKで3月放送（ITmedia NEWS）,https://news.yahoo.co.jp/articles/0d7f7685016ca2f8b75f9f3b3288fd09ec53f4cd,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000085-zdn_n-000-1-view.jpg?exp=10800,2025-02-10T15:57:05+09:00,2025-02-10T15:57:05+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,519,"「はーい！ミャクミャクです」(C)Expo 2025
NHKは2月10日、「2025大阪・関西万博」の公式キャラクター「ミャクミャク」が主人公のアニメ「はーい！ミャクミャクです」を3月に放送すると発表した。
【画像】主人公のミャクミャクとキャストの説明
1話2分の短編アニメ。NHK総合で3月3日から6日まで、4夜連続で2話ずつ計8話を放送する。放送時間は午後11時45分から。

　ミャクミャクは、35億年前に誕生した不思議ないきもの。いのちや未来について誰かと話してみたくなり、ある街にやってきて……というストーリー。ミャクミャクと出会う人々の会話が“クスっと笑える”ハートフルコメディだという。

　アニメ制作はファンワークスで、監督は沼口雅徳さんが務める。ミャクミャクの声は声優の水野なみさんが担当した。

　2025年日本国際博覧会協会は「現代の4コマ漫画を意識したショートアニメ。大阪・関西万博の開催意義と万博のテーマ『いのち輝く未来社会のデザイン』を訴求し、アニメをご覧いただいた方が登場するキャラクターを通して『万博で未知の出会い・体験を果たしたい』という気持ちになっていただければ」としている。
ITmedia NEWS",[],[]
「モンハンワイルズ」βテスト中にPSNで丸一日の障害　SIEは補てん発表も「中間報告ほしかった」の声　（ITmedia NEWS）,https://news.yahoo.co.jp/articles/d89a009b647eed1f291c929978cbeeb15339b2b8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000075-zdn_n-000-1-view.jpg?exp=10800,2025-02-10T13:33:52+09:00,2025-02-10T13:33:52+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,846,"（出典：Ask PlayStation JP）
ソニー・インタラクティブエンタテインメントは、2月8日に発生した「PlayStation Network」（PSN）の障害を受け、「PlayStation Plus」加入者全員に自動的にサービス期間を延長すると発表した。新作ゲーム「モンスターハンターワイルズ」の第2回オープンβテストを行っていたカプコンも補てんを検討しているという。
【画像】障害発生と復旧のアナウンス。ほぼ24時間掛かったが、その間、途中経過や見通しについてのアナウンスはなかった
プレイステーションのカスタマーサポートが運営する公式Xアカウントが9日に明らかにした。今回の接続障害は「運用の不具合」と説明し、ユーザーに謝罪し、補てんとして「PlayStation Plus」加入者全員に自動的にサービス期間を5日間延長するという。

　カプコンも9日、PSNの障害によってオープンβテストに参加できなくなったユーザーに対し「テスト期間が大きく削られてしまった状況を鑑み、来週末以降に約24時間分の追加実施ができないか、現在検討を行なっている」と公式Xで表明した。オープンβテストは2月7～10日と、2月14～17日の二度にわたり、全ての対応プラットフォームで開催するスケジュールになっているが、PS5ユーザーのみ丸一日減ってしまうことになるためだ。

　障害が発生したのは土曜日の朝。SIEは8日の午前9時12分に「PlayStation Storeを含むPlayStation Networkが利用できない場合がある」とX上で報告し、調査と復旧作業を行っているためユーザーにしばらく待つように伝えた。

　しかし復旧のアナウンスがあったのは、丸一日が経過した9日午前9時5分だった。その間、途中経過や見通しについての報告はなく、一部ユーザーからは「社会人にとって土曜日は貴重（な休日）」「ユーザーが欲しいのは中間報告」といった声も上がっていた。
ITmedia NEWS",[],[]
同じ「Deep Research」でもこんなに違う　Googleは“ウェイ系陽キャ”、ChatGPTは静かでまじめ（ITmedia NEWS）,https://news.yahoo.co.jp/articles/48a406a0653c8cc933e70f63a5804f376bc5f92a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000065-zdn_n-000-2-view.jpg?exp=10800,2025-02-10T11:30:23+09:00,2025-02-10T13:01:05+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1943,"（写真：ITmedia NEWS）
ITmedia NEWS Weekly AccessTop10（2月1～7日）

1　幼稚園の壊れた看板、パソコン工房が弁償へ　「RTX 5090」店頭抽選の混乱を謝罪
2　「見積もりが甘かった」　パソコン工房、騒動に至った経緯を説明
3　超初心者向けの“RAW現像入門”的な話
4　デジタル一眼とスマホカメラの“現在地”　いろいろなシチュエーションで比較してみた
5　NHK、システム開発めぐり日本IBMを提訴　54億7000万円請求　IBM「協議を重ねて申し入れてきた」
6　ナナフシで“まれに生まれるオス”は、メスと交尾しても遺伝子を残せないと判明　基礎生物学研などが調査
7　とんがり頭の「OM-3」登場　フィルム時代を彷彿とさせるボディにフラグシップと同じセンサー搭載
8　「Switch 2」転売対策か、本人確認義務化への対応か？　任天堂、公式ストアで海外クレカなど取り扱いを終了
9　Switch 2は「お求めやすい価格考慮」――任天堂の古川社長が決算説明会で明かしたこと
10　「は」の直後に「、」は必要か？　論文60本を分析、使い分けの基準を提示　筑波大と琉球大が発表
【画像を見る】Google（Gemini Advanced Deep Research）のリサーチ結果より【全6枚】
ITmedia NEWSにおける1週間の記事アクセス数を集計し、上位10記事を紹介する「ITmedia NEWS Weekly Top10」。今回は2月1～7日までの7日間について集計し、まとめた。

　集計対象外だが先週は、ChatGPTに調査エージェント機能「deep research」が追加され、関連の記事も話題になった。ネット上を深く調査し、詳細なレポートを出してくれるAIエージェントで「人間が数時間かけて調査する作業を数十分で完了できる」とアピールしている。

　「Deep Research」という名前の機能は、Googleの生成AIシリーズ「Gemini」にも以前から実装されている。ChatGPTのdeep research同様、調査レポートに特化したAIエージェントだ。

　名前も目的も同じこの2つの機能を、同じ調査をお願いして使い比べてみた。
Googleは“ウェイ系陽キャ”、ChatGPTは静かでまじめ
調べたのは「東京から香川の1泊旅行」のスケジュール。「2月8日出発」「一定のクオリティーを保ちながら格安」「名所を一通り回りたい」という希望を出した。

　それぞれ、Webの記事を詳しく検索しながら結果をまとめるため、数分程度待つ必要があるが、Googleの方が倍以上高速な印象だ。レポート内容は、Googleがやや雑、ChatGPTは遅いがとても精密、という印象を受けた。

　1日のスケジュールに関しては、Googleが半日単位でざっくりとした予定を出してくるのに対して、ChatGPTは数十分から1時間単位で詳しくプランニングしてくれる。リサーチ結果の正確さは検証していないが、ChatGPTの結果はそのまま旅行プランとしてトレースして使える精密さだ。

　ちなみにGoogleは、レポートの冒頭で高速バス移動を推奨したのに、その後の交通費の概算では高松空港からのリムジンバス費用を出すなど、一見して分かる矛盾もあった。

　加えてGoogleは「旅行前に、香川の天気予報を確認しておきましょう」など、聞いていないことにまで口を出してくる。狙った結果を出そうと検索を繰り返していると「魅力満載のうどん県を満喫！」などノリノリのプランまで立ててくるなど、ノリで押し切る“ウェイ系陽キャ”っぽいな、と感じた。

　ChatGPTは1回で必要十分な結果を出してくれたので、検索を繰り返す必要性を感じなかった。沈思黙考型で、オーダーされた内容をかみ砕いて正確なアウトプットを心掛ける、まじめなモデルだ。

　使いやすさは一長一短。Googleは月額2900円（AIプレミアムプラン）で利用でき、Deep Reserach利用の回数制限がない上に検索スピードが速い。GPTのほうは月額200ドル（＋消費税／日本円で約3.5万円）の最高額プランが必要で、利用は月100回まで。検索スピードはゆっくりだ。

　Google GeminiのDeep Researchはスピーディーで提案力があり、回数を気にせず使える。ChatGPTは精密で的確なアウトプットを出すが、使える数が限られている。即時性や回数を求めるならGemini、丁寧な調査を重視するならChatGPTが向いていると言えそうだ。
ITmedia NEWS",[],[]
Metaが深層学習「Brain2Qwerty」を発表、脳波から文章解読（ITmedia NEWS）,https://news.yahoo.co.jp/articles/bd5df12d433cd43d28d6f9b2d3b5284cea1ca5b9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000058-zdn_n-000-1-view.jpg?exp=10800,2025-02-10T10:06:59+09:00,2025-02-10T10:06:59+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1052,"（写真：ITmedia NEWS）
米Metaは2月7日（現地時間）、新しいディープラーニング（深層学習）アーキテクチャ「Brain2Qwerty」を発表した。非侵襲的な方法で脳活動から文章を解読することに成功したとしている。この研究は、脳損傷によってコミュニケーション能力を失った人々が、再び意思疎通を図れるようになる未来を拓く可能性を持っているという。
実験中のボランティア（画像：Meta）
Brain2Qwertyは、人間がQWERTYキーボードで文章を入力している際の脳波（EEG）または脳磁図（MEG）から文章を解読するように訓練されている。

　この研究では、35人の健康なボランティアを対象に、Brain2Qwertyの有効性が実証されたという。参加者が文章を入力している際の脳活動を記録し、AIモデルを訓練して脳信号から文章を再構築した。

　この実験では、脳信号から文字を解読する精度が最大80％に達し、文章の再構築に成功した。

　Metaは、脳が思考を言葉の配列に変換する仕組みをAIで解明する研究も行っている。毎秒1000回の脳のスナップショットを解析し、思考が単語、音節、文字に変換される瞬間を特定する研究により、脳が文の意味のような抽象的なレベルから指の動きのような具体的な行動へと、段階的に情報を変換する過程が明らかになってきているという。

　この研究は、非侵襲的なBCI（ブレインコンピュータインタフェース）の開発に繋がり、脳の言語生成の神経メカニズムの解明はAMI（高度な機械知能）の開発に貢献する可能性があるとMetaは説明している。

　ただし、この研究にはまだ課題が多い。文字誤り率（CER）の平均は32％（つまり、3文字に1文字程度の率で誤っている）だ。また、MEGを使うには、しっかり磁気シールドされた部屋の中で、被検者を動かないよう固定する必要がある。

　Meta（当時はFacebook）は2017年、“10年先に実現する見込みの技術”の1つとして、脳で考えたことをダイレクトに出力するシステムの構想を発表している。2021年には、脳からの神経信号を読み取り、タイピングやスマートホーム端末の操作、ゲームなどをジェスチャーで行えるようにするリストバンド式のAR（拡張現実）インタフェースの計画を発表した。

　イーロン・マスク氏が創業した米NeuralinkもBCIを開発中。こちらは脳にチップを埋め込む侵襲的なシステムだ。
ITmedia NEWS",[],[]
3年間毎月15万円を、無条件に支給──サム・アルトマンが関わるベーシックインカム実験　結果は？（ITmedia NEWS）,https://news.yahoo.co.jp/articles/52434be0547105611c98547ae9db52b7123f0859,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000036-zdn_n-000-1-view.jpg?exp=10800,2025-02-10T08:05:16+09:00,2025-02-10T08:05:16+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1838,"研究チーム「OpenResearch」がベーシックインカムに関する社会実験の結果を公開
OpenAIのサム・アルトマンCEOが取締役を務める研究チーム「OpenResearch」が、ベーシックインカムに関する社会実験の結果を公開している。この研究は、米国における無条件の現金給付に関する包括的な実地調査であり、受給者の生活実態や行動変化を多角的に分析したものである。
【画像を見る】飲酒は20％減少し、鎮痛剤の使用は53％減少【全3枚】
米国の低所得成人1000人への毎月1000ドルの現金給付が、個人の意思決定や生活の質にどのような影響を及ぼすかを、政治的態度、自己決定能力、健康、雇用、支出の5つの主要な観点から検証している。対照群として、2000人に毎月50ドルを支給し、これらを3年間続けた。結果は次に示す通りである。

　政治的態度と行動への影響については、投票行動や政治的選好に大きな変化は見られなかった。しかし、仕事に対する認識において変化が観察でき、個人や社会にとっての仕事の重要性、さらには政府プログラムへのアクセスにおける仕事の必要性についての認識が強まった。

　労働時間の減少は見られたものの、これは仕事の価値を軽視したためではなく、むしろ自身のゴールや家族のニーズにより適した雇用を選択できる余地が生まれたことを示している。

　自己決定能力の面では、予算管理や将来計画の立案、教育機会の追求、起業への関心において顕著な向上が見られた。具体的には、教育や職業訓練を受講した確率が対照群と比較して平均14％上昇し、低所得者に関していえば34％と高い上昇をみせた。

　予算管理を実施する確率も5％増加し、財務管理に費やす時間も1カ月当たり約20分多くなった。

　受給者は起業家精神を持つ可能性が高く、対照群と比較して8％上昇した。特筆すべきは、黒人受給者の起業率は対照群と比較して26％上昇し、女性受給者では15％増加した。これらの結果は、現金給付が個人の目標設定と実現に向けた具体的な行動を促進する効果があることを示唆している。

　医療サービスの利用においては、救急医療や外来診療、特に歯科治療や専門医への受診が増加。歯科治療を受ける確率は対照群と比べて10％以上、医療支出は月平均20ドル増加した（健康保険料は含まれていない）。また、日常生活に支障を来すような飲酒が20％減少、処方されていない鎮痛剤を使用する日数が53％減少するなど、健康的な生活習慣への好影響も観察できた。
他者への経済的支援も増加　“助け合い”を促進か
雇用状況については、登録時点でCOVID-19の影響があり受給者の失業率が高かったことを踏まえなければならない。登録時の受給者の就業率は58％で、対照群は59％であった。プログラムの最終月には、就業率は受給者で72％、対照群で74％に上昇した。

　受給者は、対照群に比べて、積極的に仕事を探している可能性が10％高く、仕事に応募する可能性が9％高かったが、応募した仕事の数は少なかった。受給者は、どんな仕事でも必須の条件として、興味深い仕事や有意義な仕事を選択する傾向が高かった。

　現金給付プログラムの世帯収入への影響を分析したところ、給付金自体を除外して考えると、受給者の世帯総収入は2500～4100ドル減少し、対照群を下回っていた。ただし、月々の給付金1000ドルを含めて計算すると、受給者の平均個人収入は約1万ドル、平均世帯収入は約6100ドルと対照群を上回る結果となった。

　支出パターンの分析では、月平均310ドルの支出増加を確認し、その内訳は食費（67ドル増）、交通費（50ドル増）、家賃（52ドル増）など、基本的なニーズに関連する項目が中心であった。

　特筆すべき点として、他者への経済的支援が26％増加し、月平均22ドルの支出増となったことが挙げられる。この支出増加は、現金給付が個人の生活基盤を安定させるだけでなく、コミュニティー内での相互扶助を促進する効果があることを示唆している。

　※Innovative Tech：このコーナーでは、2014年から先端テクノロジーの研究を論文単位で記事にしているWebメディア「Seamless」（シームレス）を主宰する山下裕毅氏が執筆。新規性の高い科学論文を山下氏がピックアップし、解説する。X： ＠shiropen2
ITmedia NEWS",[],[]
耳をぴくぴく動かす「退化した筋肉」、ある状況で活躍しており意味があった　ドイツなどの研究者らが発見（ITmedia NEWS）,https://news.yahoo.co.jp/articles/42cc1a621af19ebddce72d6afb093014f7dbfa23,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250210-00000035-zdn_n-000-1-view.jpg?exp=10800,2025-02-10T08:05:13+09:00,2025-02-10T08:05:13+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1252,"（写真：ITmedia NEWS）
ドイツのザールラント大学などに所属する研究者らが発表した論文「Electromyographic correlates of effortful listening in the vestigial auriculomotor system」は、人間の耳介筋（耳の周りの筋肉）の活動と音を聞き分けようとする際の脳の働きとの関係について調査した研究報告である。
【画像を見る】耳介筋の筋電図を計測する電極を装着した様子【全3枚】
人間は耳を動かす能力が退化したが、この特徴を支える筋肉や脳神経の一部は現代の人にも残っている。最新の研究では、これらの耳介筋が音を聞き分ける際の生理学的な指標として機能している可能性を示唆している。

　この研究では、20人の健常な参加者（平均28歳）を対象に実験を行った。参加者は防音空間内で、前方または後方のスピーカーから流れる目的の音声（50dBの女性話者）を聞き取りながら、同時に再生される妨害音声を無視するように指示を受けた。その際、参加者には耳に電極を取り付け、上耳介筋と後耳介筋の筋電図を記録した。

　実験は3つの難易度で実施。全条件において目的の音声は50 dB LAeq（騒音レベルを示す単位）の女性話者で一定とされた。最も簡単な条件では目的の音声より10dB小さい1つの妨害音声（40 dB LAeq、男性話者）、中程度の条件では2dB小さい2つの妨害音声（45 dB LAeq、女性話者と男性話者）、最も困難な条件ではSNR（信号対雑音比）が-2dBとなる2つの妨害音声（49 dB LAeq、女性話者と男性話者）を使用した。

　研究の結果、上耳介筋の活動は、最も困難な条件で有意に大きくなることが判明した。これは、人間が音を聞き分けようと努力する際に、耳の形を変えようとする原始的な反射が働いている可能性を示唆している。一方、後耳介筋は音源の位置に反応し、音が後方から来る場合に活動が大きくなった。

　Source and Image Credits: Schroeer A, Corona-Strauss FI, Hannemann R, Hackley SA and Strauss DJ（2025）Electromyographic correlates of effortful listening in the vestigial auriculomotor system. Front. Neurosci. 18:1462507. doi: 10.3389/fnins.2024.1462507

　※Innovative Tech：このコーナーでは、2014年から先端テクノロジーの研究を論文単位で記事にしているWebメディア「Seamless」（シームレス）を主宰する山下裕毅氏が執筆。新規性の高い科学論文を山下氏がピックアップし、解説する。X： ＠shiropen2
ITmedia NEWS",[],[]
